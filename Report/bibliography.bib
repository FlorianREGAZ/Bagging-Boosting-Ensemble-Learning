@article{1106.0257,
  Author = {R. Maclin and D. Opitz},
  Title = {Popular Ensemble Methods: An Empirical Study},
  Year = {2011},
  Eprint = {arXiv:1106.0257},
  Howpublished = {Journal Of Artificial Intelligence Research, Volume 11, pages 169-198, 1999},
  Doi = {10.1613/jair.614},
}

@Article{Breiman1996,
  author={Breiman, Leo},
  title={Bagging predictors},
  journal={Machine Learning},
  year={1996},
  month={Aug},
  day={01},
  volume={24},
  number={2},
  pages={123-140},
  abstract={Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.},
  issn={1573-0565},
  doi={10.1007/BF00058655},
  url={https://doi.org/10.1007/BF00058655}
}

@Article{Schapire1990,
  author={Schapire, Robert E.},
  title={The strength of weak learnability},
  journal={Machine Learning},
  year={1990},
  month={Jun},
  day={01},
  volume={5},
  number={2},
  pages={197-227},
  abstract={This paper addresses the problem of improving the accuracy of an hypothesis output by a learning algorithm in the distribution-free (PAC) learning model. A concept class islearnable (orstrongly learnable) if, given access to a source of examples of the unknown concept, the learner with high probability is able to output an hypothesis that is correct on all but an arbitrarily small fraction of the instances. The concept class isweakly learnable if the learner can produce an hypothesis that performs only slightly better than random guessing. In this paper, it is shown that these two notions of learnability are equivalent.},
  issn={1573-0565},
  doi={10.1007/BF00116037},
  url={https://doi.org/10.1007/BF00116037}
}

@inproceedings{freund1996experiments,
  title={Experiments with a new boosting algorithm},
  author={Freund, Yoav and Schapire, Robert E and others},
  booktitle={icml},
  volume={96},
  pages={148--156},
  year={1996},
  organization={Citeseer}
}


@misc{breast_cancer_wisconsin,
  author       = {Wolberg, William and Mangasarian, Olvi and Street, Nick and Street, W.},
  title        = {Breast Cancer Wisconsin (Diagnostic)},
  year         = {1995},
  howpublished = {UCI Machine Learning Repository},
  note         = {DOI: https://doi.org/10.24432/C5DW2B}
}

