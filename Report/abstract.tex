\section*{Abstract}

Ensemble Learning is a very powerful machine learning method, which combines
multiple smaller learning algorithms. Previous research has shown that 
ensembles often achieve higher predictive accuracy than individual learning
algorithms in the ensemble.
In this report, we explain the Ensemble Learning methods Bagging \citep*{Breiman1996},
Boosting \citep*{Schapire1990}, Random Forest \citep*{breiman2001random},
and Gradient Boosting \citep*{breiman1997arcing, friedman2001greedy, friedman2002stochastic},
and compare them against Decision Trees.
Our evaluation demonstrates a significant improvement in predictive accuracy
with Ensemble Learning methods. The results indicate that methods like Bagging,
Boosting, Random Forests, and Gradient Boosting consistently outperform Decision Trees.
These findings underscore the potential of Ensemble Learning in advancing the field of 
machine learning, offering valuable insights for data scientists in model selection and 
application.

